---
layout: template
menu : tutorial
title : Parallel jobs
---

              <h2 id="1">1. Introduction</h2>

              <p>The core engine of Easy Batch implements the <code><em>java.util.concurrent.Callable</em></code> interface.
                  This turns it into a unit of work that can be submitted to a <code><em>java.util.concurrent.ExecutorService</em></code>.</p>
              <p>Using the <code><em>java.util.concurrent.ExecutorService</em></code> with a pool of threads allows you
                  to run multiple Easy Batch instances in parallel. There are at least 3 ways to process data in parallel:</p>
              <ol>
                  <li>Distributing input records to multiple batch engines</li>
                  <li>Physical partitioning of the data source into multiple physical parts which will be processed by separate engines</li>
                  <li>Logical partitioning of the data source into multiple logical parts which will be processed by separate engines</li>
              </ol>

                <p>In this tutorial, you will see an example of implementing each of these techniques using Easy Batch.</p>

              <p>You will reuse the same application developed in the <a href="./helloworld.html">Hello world tutorial</a> but with a huge tweets data source:</p>

<div class="bs-callout bs-callout-code">
    <h5>tweets.csv</h5>
<pre><code>id,user,message
1,foo,easy batch rocks! #EasyBatch
2,bar,@foo I do confirm :-)
...
10000000,baz,@foo @bar what are you talking about? Am I in trouble?
</code></pre>
</div>

        <h2>2. Dispatching records</h2>

<p>In order to distribute work to multiple engines, Easy Batch provides the <code><em>AbstractRecordDispatcher</em></code> API:</p>

        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <p class="pull-center"><img class="ebi" src="../img/eb/dispatcher.jpg"/></p>
            </div>
        </div>

        <p>There are 4 built-in implementations of the <code><em>AbstractRecordDispatcher</em></code> API. Please refer to the
            <a href="../documentation/user-guide.html">user guide</a> (section "miscellaneaous") for all details about available record dispatchers.
        In this tutorial, you will learn how to use the <code><em>RoundRobinRecordDispatcher</em></code> to distribute tweets to 2 queues.</p>

<div class="bs-callout bs-callout-warning">
    <h5><i class="fa fa-info-circle"></i> Heads up!</h5>
    <p>Poison records serve as End-Of-Stream messages, they are used to stop the engine (gracefully).</p>
    <p>Easy Batch provides the <code><em>PoisonRecord</em></code> utility class to stop the engine when all data has been read.
        Poison records have no business value, you should filter them using the convenient built-in <code><em>PoisonRecordFilter</em></code>.</p>
</div>

        <p>We will create a "master" engine that will read data from the input file and use a <code><em>RoundRobinRecordDispatcher</em></code>
        to distribute records to "worker" engines. Each worker engine will read data from a queue which holds the work that is assigned to it:</p>

        <div class="bs-callout bs-callout-code">
<pre><code class="java">public class ParallelTutorialWithRecordDispatching {

        private static final int THREAD_POOL_SIZE = 3;

        public static void main(String[] args) throws Exception {

        // Input file tweets.csv
        File tweets = new File(args[0]);

        // Create queues
        BlockingQueue&lt;Record&gt; queue1 = new LinkedBlockingQueue&lt;Record&gt;();
        BlockingQueue&lt;Record&gt; queue2 = new LinkedBlockingQueue&lt;Record&gt;();

        // Create a round robin record dispatcher
        RoundRobinRecordDispatcher roundRobinRecordDispatcher
                = new RoundRobinRecordDispatcher(Arrays.asList(queue1, queue2));

        // Build a master engine that will read records from the data source
        // and dispatch them to worker engines
        Engine masterEngine = aNewEngine()
            .reader(new FlatFileRecordReader(tweets))
            .processor(roundRobinRecordDispatcher)
            .batchProcessEventListener(new PoisonRecordBroadcaster(roundRobinRecordDispatcher))
            .build();

        // Build worker engines
        Engine workerEngine1 = buildWorkerEngine(queue1);
        Engine workerEngine2 = buildWorkerEngine(queue2);

        // Create a thread pool to call master and worker engines in parallel
        ExecutorService executorService = Executors.newFixedThreadPool(THREAD_POOL_SIZE);

        // Submit workers to executor service
        executorService.submit(masterEngine);
        executorService.submit(workerEngine1);
        executorService.submit(workerEngine2);

        // Shutdown executor service
        executorService.shutdown();

    }

    public static Engine buildWorkerEngine(BlockingQueue&lt;Record&gt; queue) {
        return aNewEngine()
            .reader(new QueueRecordReader(queue))
            .filter(new PoisonRecordFilter())
            .processor(new TweetProcessor())
            .build();
    }

}</code></pre>
</div>

        <p>The record dispatcher dispatches records to a <code><em>java.util.concurrent.BlockingQueue</em></code>.
        We should be able to read data from this type of queues. Easy Batch comes with a built-in <code><em>QueueRecordReader</em></code> to
        save you from writing the reading code yourself. When the master engine finishes reading the data source, it sends a <code><em>PoisonRecord</em></code>
            using the <code><em>PoisonRecordBroadcaster</em></code> to stop worker engines.</p>

        <h2>3. Splitting the data source</h2>

        <p>It is a common technique to split the data source into multiple slices as follow:</p>

<div class="row">
    <div class="col-md-10 col-md-offset-1">
        <p class="pull-center"><img class="ebi" src="../img/eb/split.jpg"/></p>
    </div>
</div>

        <p>Easy Batch does not provide a feature to partition input data. If you decided to split your data source into multiples parts,
        you can still use Easy Batch to process them in parallel using a <code><em>java.util.concurrent.ExecutorService</em></code>.
            Here is a sample of how to use multiple engines to process multiple data source parts in parallel:</p>

        <div class="bs-callout bs-callout-code">
<pre><code class="java">public class ParallelTutorialWithDataSplitting {

    private static final int THREAD_POOL_SIZE = 2;

    public static void main(String[] args) throws Exception {

        // Input file tweets-part1.csv
        File tweetsPart1 = new File(args[0]);

        // Input file tweets-part2.csv
        File tweetsPart2 = new File(args[1]);

        // Build worker engines
        Engine engine1 = buildEngine(tweetsPart1);
        Engine engine2 = buildEngine(tweetsPart2);

        //create a 2 threads pool to call worker engines in parallel
        ExecutorService executorService = Executors.newFixedThreadPool(THREAD_POOL_SIZE);

        Future&lt;Report&gt; report1 = executorService.submit(engine1);
        Future&lt;Report&gt; report2 = executorService.submit(engine2);

        //merge partial reports into a global one
        ReportMerger reportMerger = new DefaultReportMerger();
        Report finalReport = reportMerger.mergerReports(report1.get(), report2.get());
        System.out.println(finalReport);

        executorService.shutdown();
    }

    private static Engine buildEngine(File file) throws Exception{
        return new EngineBuilder()
            .reader(new FlatFileRecordReader(file))
            .processor(new TweetProcessor())
            .build();
    }
}</code></pre>
        </div>

<p>In this example, we have distributed the work across multiple engines, so we will get partial reports at the end of execution of each worker engine.
    How do we get a global report for all the work? This is where the <code><em>ReportMerger</em></code> comes to play,
    that is, to merge partial reports into a global one.</p>

<div class="bs-callout bs-callout-warning">
    <h5><i class="fa fa-info-circle"></i> Heads up!</h5>
    <p>In this example, you have used multiple threads within the same JVM to process data in parallel.
        You could also launch separate JVMs for each part.</p>
</div>

        <p>Another possibility to process multiple input files in parallel is to use a master engine with a <code><em>FileRecordReader</em></code> coupled to a record dispatcher:</p>

<div class="row">
    <div class="col-md-10 col-md-offset-1">
        <p class="pull-center"><img class="ebi" src="../img/eb/files.jpg"/></p>
    </div>
</div>

        <p>This gives the same setup as in section 2. The <code><em>FileRecordReader</em></code> reads files from a directory and produces <code><em>FileRecord</em></code> instances having <code><em>java.io.File</em></code> as payload.</p>
        <p>The record dispatcher can then distribute files to worker engines. You can use a <code><em>RoundRobinRecordDispatcher</em></code> to distribute workload in a uniform way or use a <code><em>ContentBasedRecordDispatcher</em></code>
        to distribute files according to their type (for example: CSV files go to worker1, XML files to worker2, etc)</p>
        <p>This configuration is not implemented in this tutorial.</p>

<h2>4. Filtering the data source</h2>

        <p>Sometimes it is just impossible to split the data source into multiple physical parts. The third technique is to use a single data source
        but to instruct worker engines to process separate parts and filter the rest of the data source.</p>

        <p>Let's see an example:</p>

<div class="row">
    <div class="col-md-10 col-md-offset-1">
        <p class="pull-center"><img class="ebi" src="../img/eb/filter.jpg"/></p>
    </div>
</div>

              <ul>
                  <li>The first engine instance will read data from <code>tweets.csv</code> file, process records 1-2 and filter records 3-4.</li>
                  <li>The second engine instance will also read data from <code>tweets.csv</code> file, process records 3-4 and filter records 1-2.</li>
              </ul>

              <p>The following listing shows the code to achieve this configuration:</p>

        <div class="bs-callout bs-callout-code">
<pre><code class="java">public class ParallelTutorialWithDataFiltering {

    private static final int THREAD_POOL_SIZE = 2;

    public static void main(String[] args) throws Exception {

        // Input file tweets.csv
        File tweets = new File(args[0]);

        <strong>// worker engine 1: process data from tweets.csv, filter records 3-4
        Engine engine1 = buildEngine(tweets, new RecordNumberGreaterThanFilter(2));

        // worker engine 2: process data from tweets.csv, filter records 1-2
        Engine engine2 = buildEngine(tweets, new RecordNumberLowerThanFilter(3));</strong>

        //create a 2 threads pool to call worker engines in parallel
        ExecutorService executorService = Executors.newFixedThreadPool(THREAD_POOL_SIZE);

        Future&lt;Report&gt; report1 = executorService.submit(engine1);
        Future&lt;Report&gt; report2 = executorService.submit(engine2);

        //merge partial reports into a global one
        ReportMerger reportMerger = new DefaultReportMerger();
        Report finalReport = reportMerger.mergerReports(report1.get(), report2.get());
        System.out.println(finalReport);

        executorService.shutdown();
    }

    private static Engine buildEngine(File file, RecordFilter recordFilter) throws Exception{
        return new EngineBuilder()
            .reader(new FlatFileRecordReader(file))
            .filter(recordFilter)
            .processor(new TweetProcessor())
            .build();
    }
}</code></pre>
        </div>

              <h2>5. Running the tutorial</h2>

        <h3>5.1 From the command line</h3>

<p>To run the tutorials, proceed as follow:</p>
<div class="bs-callout bs-callout-code">
<pre><code>$>git clone https://github.com/benas/easy-batch.git
$>cd easy-batch
$>mvn install
$>cd easybatch-tutorials
$> # Launch the record dispatching tutorial
$>mvn exec:java -PrunParallelTutorialWithRecordDispatching
$> # Launch the data source splitting tutorial
$>mvn exec:java -PrunParallelTutorialWithDataSplitting
$> # Launch the data source filtering tutorial
$>mvn exec:java -PrunParallelTutorialWithDataFiltering
</code></pre>
</div>

<h3>5.2 From your IDE</h3>

<p>First, you need to checkout the source code of the tutorial available <a href="https://github.com/benas/easy-batch/tree/master/easybatch-tutorials/src/main/java/org/easybatch/tutorials/advanced/parallel" target="_blank">here</a>:</p>

<div class="bs-callout bs-callout-code">
    <pre><code>$>git clone https://github.com/benas/easy-batch.git</code></pre>
</div>

<p>If you do not have git installed, you can download a zip file containing the project's source code from GitHub
    <a href="https://github.com/benas/easy-batch/archive/easybatch-{{ site.version }}.zip">here</a>.</p>

<p>Then, import the <code><em>easybatch-tutorials</em></code> module in you favorite IDE and resolve maven dependencies.</p>

<p>Finally, run the one of the following classes without any argument:</p>
<ul>
    <li><code><em>org.easybatch.tutorials.advanced.parallel.ParallelTutorialWithDataFiltering</em></code></li>
    <li><code><em>org.easybatch.tutorials.advanced.parallel.ParallelTutorialWithDataSplitting</em></code></li>
    <li><code><em>org.easybatch.tutorials.advanced.parallel.ParallelTutorialWithRecordDispatching</em></code></li>
</ul>

<h2>6. Summary</h2>

              <p>In this tutorial, you have seen at least 3 ways of how to process data in parallel using multiple worker engines
                  in order to speed up the overall processing time.</p>
              <p>The following table summarizes the advantages and drawbacks for each approach:</p>
              <table class="table table-bordered table-condensed ">
                  <thead>
                  <tr class="alert-info">
                      <th>Approach</th>
                      <th>Advantages</th>
                      <th>Drawbacks</th>
                  </tr>
                  </thead>
                  <tbody>
                  <tr>
                      <td>Dispatching records (no partitioning)</td>
                      <td><span class="text-success">Best way to distribute work across multiple worker engines.</span></td>
                      <td><span class="text-danger">Need to setup an additional record reader and queues.</span></td>
                  </tr>
                  <tr>
                      <td>Splitting the data source<br>(physical partitioning)</td>
                      <td><span class="text-success">Each engine reads only its own part and not the entire data source</span></td>
                      <td><span class="text-danger">Need to split the data source into multiple parts</span></td>
                  </tr>
                  <tr>
                      <td>Filtering the data source<br>(logical partitioning)</td>
                      <td><span class="text-success">No need to split the input data source into multiple parts</span></td>
                      <td><span class="text-danger">Each engine will read the entire data source</span></td>
                  </tr>
                  </tbody>
              </table>

        <p>Using a record dispatcher should be your first choice when dealing with data processing in parallel
            because it is more efficient than other techniques and provides the most natural way of distributing the work across multiple engines.</p>

<h2>7. What's next?</h2>

<p>In the next, you will learn how to process data asynchronously using a JMS queue.</p>

<nav>
    <ul class="pager">
        <li class="previous"><a href="./spring.html"><span aria-hidden="true">&larr;</span> Spring tutorial</a></li>
        <li class="next"><a href="./jms.html">Asynchronous jobs tutorial<span aria-hidden="true">&rarr;</span></a></li>
    </ul>
</nav>

